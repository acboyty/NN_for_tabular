{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('py37_pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b5079757533a07d523b22964b5bda6a42550d36e9c94eb5f662e38c34376cbf3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already up-to-date: deepctr-torch in /home/v-tyan/.local/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: sklearn in /home/v-tyan/.local/lib/python3.7/site-packages (from deepctr-torch) (0.0)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /home/v-tyan/.local/lib/python3.7/site-packages (from deepctr-torch) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from deepctr-torch) (4.50.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow in /home/v-tyan/.local/lib/python3.7/site-packages (from deepctr-torch) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from sklearn->deepctr-torch) (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from torch>=1.1.0->deepctr-torch) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from torch>=1.1.0->deepctr-torch) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: grpcio~=1.32.0 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (1.32.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (1.12)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py~=2.10.0 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard~=2.4 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorflow->deepctr-torch) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from scikit-learn->sklearn->deepctr-torch) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from scikit-learn->sklearn->deepctr-torch) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from scikit-learn->sklearn->deepctr-torch) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->deepctr-torch) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->deepctr-torch) (0.4.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->deepctr-torch) (50.3.0.post20201103)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->deepctr-torch) (3.3.3)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->deepctr-torch) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->deepctr-torch) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /home/v-tyan/.local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow->deepctr-torch) (1.24.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->deepctr-torch) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->deepctr-torch) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->deepctr-torch) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->deepctr-torch) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->deepctr-torch) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->deepctr-torch) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/v-tyan/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->deepctr-torch) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /home/v-tyan/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->deepctr-torch) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /home/v-tyan/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->deepctr-torch) (4.2.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->deepctr-torch) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /anaconda/envs/py37_pytorch/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow->deepctr-torch) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /home/v-tyan/.local/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->deepctr-torch) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U deepctr-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr_torch.models import DeepFM\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import StringIO\n",
    "import re \n",
    "import pickle\n",
    "import scipy.io.arff\n",
    "from torch.optim import Adam\n",
    "\n",
    "dataset_path = \"/home/v-tyan/NN_for_tabular/datasets_raw/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  Var10  ...  \\\n",
       "0       NaN   NaN   NaN   NaN   NaN  1526.0   7.0   NaN   NaN    NaN  ...   \n",
       "1       NaN   NaN   NaN   NaN   NaN   525.0   0.0   NaN   NaN    NaN  ...   \n",
       "2       NaN   NaN   NaN   NaN   NaN  5236.0   7.0   NaN   NaN    NaN  ...   \n",
       "3       NaN   NaN   NaN   NaN   NaN     NaN   0.0   NaN   NaN    NaN  ...   \n",
       "4       NaN   NaN   NaN   NaN   NaN  1029.0   7.0   NaN   NaN    NaN  ...   \n",
       "...     ...   ...   ...   ...   ...     ...   ...   ...   ...    ...  ...   \n",
       "49995   NaN   NaN   NaN   NaN   NaN   357.0   0.0   NaN   NaN    NaN  ...   \n",
       "49996   NaN   NaN   NaN   NaN   NaN  1078.0   0.0   NaN   NaN    NaN  ...   \n",
       "49997   NaN   NaN   NaN   NaN   NaN  2807.0   7.0   NaN   NaN    NaN  ...   \n",
       "49998   NaN   NaN   NaN   0.0   NaN     NaN   NaN   NaN   NaN    NaN  ...   \n",
       "49999   NaN   NaN   NaN   NaN   NaN  1694.0   7.0   NaN   NaN    NaN  ...   \n",
       "\n",
       "        Var222      Var223  Var224  Var225  Var226   Var227  \\\n",
       "0      fXVEsaq  jySVZNlOJy     NaN     NaN    xb3V     RAYp   \n",
       "1      2Kb5FSF  LM8l689qOp     NaN     NaN    fKCe     RAYp   \n",
       "2      NKv4yOc  jySVZNlOJy     NaN    kG3k    Qu4f  02N6s8f   \n",
       "3      CE7uk3u  LM8l689qOp     NaN     NaN    FSa2     RAYp   \n",
       "4      1J2cvxe  LM8l689qOp     NaN    kG3k    FSa2     RAYp   \n",
       "...        ...         ...     ...     ...     ...      ...   \n",
       "49995  EROH7Cg  LM8l689qOp     NaN     NaN    7FJQ     RAYp   \n",
       "49996  GfSQowC  LM8l689qOp     NaN    kG3k    FSa2     RAYp   \n",
       "49997  dh6qI2t  LM8l689qOp     NaN    ELof    fKCe     RAYp   \n",
       "49998  2fF2Oqu  LM8l689qOp     NaN     NaN    FSa2     RAYp   \n",
       "49999  IIvC99a  LM8l689qOp     NaN     NaN    xb3V     RAYp   \n",
       "\n",
       "                    Var228  Var229  Var230  0  \n",
       "0            F2FyR07IdsN7I     NaN     NaN  1  \n",
       "1            F2FyR07IdsN7I     NaN     NaN  1  \n",
       "2            ib5G6X1eUxUn6    am7c     NaN  1  \n",
       "3            F2FyR07IdsN7I     NaN     NaN  1  \n",
       "4            F2FyR07IdsN7I    mj86     NaN  1  \n",
       "...                    ...     ...     ... ..  \n",
       "49995        F2FyR07IdsN7I     NaN     NaN -1  \n",
       "49996              55YFVY9    am7c     NaN -1  \n",
       "49997  TCU50_Yjmm6GIBZ0lL_     NaN     NaN  1  \n",
       "49998        F2FyR07IdsN7I     NaN     NaN  1  \n",
       "49999        F2FyR07IdsN7I     NaN     NaN  1  \n",
       "\n",
       "[50000 rows x 231 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Var1</th>\n      <th>Var2</th>\n      <th>Var3</th>\n      <th>Var4</th>\n      <th>Var5</th>\n      <th>Var6</th>\n      <th>Var7</th>\n      <th>Var8</th>\n      <th>Var9</th>\n      <th>Var10</th>\n      <th>...</th>\n      <th>Var222</th>\n      <th>Var223</th>\n      <th>Var224</th>\n      <th>Var225</th>\n      <th>Var226</th>\n      <th>Var227</th>\n      <th>Var228</th>\n      <th>Var229</th>\n      <th>Var230</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1526.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>fXVEsaq</td>\n      <td>jySVZNlOJy</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>xb3V</td>\n      <td>RAYp</td>\n      <td>F2FyR07IdsN7I</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>525.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2Kb5FSF</td>\n      <td>LM8l689qOp</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>fKCe</td>\n      <td>RAYp</td>\n      <td>F2FyR07IdsN7I</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5236.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NKv4yOc</td>\n      <td>jySVZNlOJy</td>\n      <td>NaN</td>\n      <td>kG3k</td>\n      <td>Qu4f</td>\n      <td>02N6s8f</td>\n      <td>ib5G6X1eUxUn6</td>\n      <td>am7c</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>CE7uk3u</td>\n      <td>LM8l689qOp</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>FSa2</td>\n      <td>RAYp</td>\n      <td>F2FyR07IdsN7I</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1029.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1J2cvxe</td>\n      <td>LM8l689qOp</td>\n      <td>NaN</td>\n      <td>kG3k</td>\n      <td>FSa2</td>\n      <td>RAYp</td>\n      <td>F2FyR07IdsN7I</td>\n      <td>mj86</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>357.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>EROH7Cg</td>\n      <td>LM8l689qOp</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7FJQ</td>\n      <td>RAYp</td>\n      <td>F2FyR07IdsN7I</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1078.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>GfSQowC</td>\n      <td>LM8l689qOp</td>\n      <td>NaN</td>\n      <td>kG3k</td>\n      <td>FSa2</td>\n      <td>RAYp</td>\n      <td>55YFVY9</td>\n      <td>am7c</td>\n      <td>NaN</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2807.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>dh6qI2t</td>\n      <td>LM8l689qOp</td>\n      <td>NaN</td>\n      <td>ELof</td>\n      <td>fKCe</td>\n      <td>RAYp</td>\n      <td>TCU50_Yjmm6GIBZ0lL_</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2fF2Oqu</td>\n      <td>LM8l689qOp</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>FSa2</td>\n      <td>RAYp</td>\n      <td>F2FyR07IdsN7I</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1694.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>IIvC99a</td>\n      <td>LM8l689qOp</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>xb3V</td>\n      <td>RAYp</td>\n      <td>F2FyR07IdsN7I</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 231 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_path, \"appetency_churn_upselling/orange_small_train.data\"), sep = \"\\t\")\n",
    "cols = list(df.columns)\n",
    "cat_cols = [cols[idx] for idx in [190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
    "            207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228]]\n",
    "num_cols = list(set(cols) - set(cat_cols))\n",
    "dataset_ = 'appetency'\n",
    "X, Y = df, -pd.read_csv(os.path.join(dataset_path, f'appetency_churn_upselling/orange_small_train_{dataset_}.labels'), header=None)[0]\n",
    "# train_idx = pd.read_csv(os.path.join(dataset_path, f'appetency_churn_upselling/{dataset_}/stratified_train_idx_{dataset_}.txt'), header=None)\n",
    "# test_idx = pd.read_csv(os.path.join(dataset_path, f'appetency_churn_upselling/{dataset_}/stratified_test_idx_{dataset_}.txt'), header=None)\n",
    "# train_X, test_X, train_Y, test_Y = X.iloc[train_idx[0]], X.iloc[test_idx[0]], Y.iloc[train_idx[0]], Y.iloc[test_idx[0]]\n",
    "columns = X.columns\n",
    "data = pd.concat((X, Y), axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = cat_cols\n",
    "dense_features = num_cols\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "target = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat].apply(str))\n",
    "# mms = MinMaxScaler(feature_range=(0,1))\n",
    "# data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Var191  Var192  Var193  Var194  Var195  Var196  Var197  Var198  Var199  \\\n",
       "0           0     142      18       0      15       0      88    2561    3354   \n",
       "1           0     354      18       0      15       0      46    2998    4325   \n",
       "2           0     167      45       2      15       0      66     764    4337   \n",
       "3           0     191      18       0      15       0     117    1752    2924   \n",
       "4           0      38      18       2      15       0     123    4260    1559   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "49995       0     271      18       0      15       0      45    3804    2784   \n",
       "49996       0      91       0       2      21       0     198    2523    4627   \n",
       "49997       0     254       0       0      15       0     149     548    3009   \n",
       "49998       1      20      18       0      15       0     155    1377     859   \n",
       "49999       0     142      18       0      15       0      14    3685    1221   \n",
       "\n",
       "       Var200  ...  Var220  Var221  Var222  Var223  Var224  Var225  Var226  \\\n",
       "0           0  ...    4225       4    2184       4       0       0      15   \n",
       "1           0  ...       2       4     280       1       0       0       6   \n",
       "2        5031  ...     328       0     681       4       0       2       2   \n",
       "3           0  ...     496       4    4089       1       0       0      20   \n",
       "4        7085  ...     815       4    3903       1       0       2      20   \n",
       "...       ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "49995       0  ...    1746       4    4257       1       0       0      16   \n",
       "49996    4574  ...     572       4     142       1       0       2      20   \n",
       "49997   14266  ...      49       4    2040       1       0       1       6   \n",
       "49998       0  ...    4111       4     469       1       0       0      20   \n",
       "49999       0  ...    2915       4     294       1       0       0      15   \n",
       "\n",
       "       Var227  Var228  Var229  \n",
       "0           2      28       0  \n",
       "1           2      28       0  \n",
       "2           0      18       1  \n",
       "3           2      28       0  \n",
       "4           2      28       2  \n",
       "...       ...     ...     ...  \n",
       "49995       2      28       0  \n",
       "49996       2      12       1  \n",
       "49997       2       6       0  \n",
       "49998       2      28       0  \n",
       "49999       2      28       0  \n",
       "\n",
       "[50000 rows x 38 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Var191</th>\n      <th>Var192</th>\n      <th>Var193</th>\n      <th>Var194</th>\n      <th>Var195</th>\n      <th>Var196</th>\n      <th>Var197</th>\n      <th>Var198</th>\n      <th>Var199</th>\n      <th>Var200</th>\n      <th>...</th>\n      <th>Var220</th>\n      <th>Var221</th>\n      <th>Var222</th>\n      <th>Var223</th>\n      <th>Var224</th>\n      <th>Var225</th>\n      <th>Var226</th>\n      <th>Var227</th>\n      <th>Var228</th>\n      <th>Var229</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>142</td>\n      <td>18</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>88</td>\n      <td>2561</td>\n      <td>3354</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4225</td>\n      <td>4</td>\n      <td>2184</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15</td>\n      <td>2</td>\n      <td>28</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>354</td>\n      <td>18</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>46</td>\n      <td>2998</td>\n      <td>4325</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>4</td>\n      <td>280</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2</td>\n      <td>28</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>167</td>\n      <td>45</td>\n      <td>2</td>\n      <td>15</td>\n      <td>0</td>\n      <td>66</td>\n      <td>764</td>\n      <td>4337</td>\n      <td>5031</td>\n      <td>...</td>\n      <td>328</td>\n      <td>0</td>\n      <td>681</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>18</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>191</td>\n      <td>18</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>117</td>\n      <td>1752</td>\n      <td>2924</td>\n      <td>0</td>\n      <td>...</td>\n      <td>496</td>\n      <td>4</td>\n      <td>4089</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>2</td>\n      <td>28</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>38</td>\n      <td>18</td>\n      <td>2</td>\n      <td>15</td>\n      <td>0</td>\n      <td>123</td>\n      <td>4260</td>\n      <td>1559</td>\n      <td>7085</td>\n      <td>...</td>\n      <td>815</td>\n      <td>4</td>\n      <td>3903</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>20</td>\n      <td>2</td>\n      <td>28</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>0</td>\n      <td>271</td>\n      <td>18</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>45</td>\n      <td>3804</td>\n      <td>2784</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1746</td>\n      <td>4</td>\n      <td>4257</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16</td>\n      <td>2</td>\n      <td>28</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>0</td>\n      <td>91</td>\n      <td>0</td>\n      <td>2</td>\n      <td>21</td>\n      <td>0</td>\n      <td>198</td>\n      <td>2523</td>\n      <td>4627</td>\n      <td>4574</td>\n      <td>...</td>\n      <td>572</td>\n      <td>4</td>\n      <td>142</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>20</td>\n      <td>2</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>0</td>\n      <td>254</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>149</td>\n      <td>548</td>\n      <td>3009</td>\n      <td>14266</td>\n      <td>...</td>\n      <td>49</td>\n      <td>4</td>\n      <td>2040</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>1</td>\n      <td>20</td>\n      <td>18</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>155</td>\n      <td>1377</td>\n      <td>859</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4111</td>\n      <td>4</td>\n      <td>469</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>2</td>\n      <td>28</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>0</td>\n      <td>142</td>\n      <td>18</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>14</td>\n      <td>3685</td>\n      <td>1221</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2915</td>\n      <td>4</td>\n      <td>294</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15</td>\n      <td>2</td>\n      <td>28</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 38 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "data[sparse_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(),embedding_dim=4) for i,feat in enumerate(sparse_features)]\n",
    "dense_feature_columns = [DenseFeat(feat, 1,) for feat in dense_features]\n",
    "dnn_feature_columns = sparse_feature_columns + sparse_feature_columns\n",
    "linear_feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\n(40000,)\ncuda ready...\ncuda:0\nTrain on 30000 samples, validate on 10000 samples, 118 steps per epoch\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "y_true contains only one label (1.0). Please provide the true labels explicitly through the labels argument.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-57e5d2822027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m               metrics=['binary_crossentropy'], )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mpred_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{log_loss(test[target].values, pred_ans):.5f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, initial_epoch, validation_split, validation_data, shuffle, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     \u001b[0mtrain_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                                 train_result[name].append(metric_fun(\n\u001b[0;32m--> 249\u001b[0;31m                                     y.cpu().data.numpy(), y_pred.cpu().data.numpy().astype(\"float64\")))\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2198\u001b[0m             raise ValueError('y_true contains only one label ({0}). Please '\n\u001b[1;32m   2199\u001b[0m                              \u001b[0;34m'provide the true labels explicitly through the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m                              'labels argument.'.format(lb.classes_[0]))\n\u001b[0m\u001b[1;32m   2201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m             raise ValueError('The labels array needs to contain at least two '\n",
      "\u001b[0;31mValueError\u001b[0m: y_true contains only one label (1.0). Please provide the true labels explicitly through the labels argument."
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = {name:train[name] for name in feature_names}\n",
    "\n",
    "test_model_input = {name:test[name] for name in feature_names}\n",
    "\n",
    "for x in train_model_input:\n",
    "    print(train_model_input[x].shape)\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "\n",
    "model = DeepFM(linear_feature_columns,dnn_feature_columns, init_std=0.1,task='binary',device=device)\n",
    "model.compile(Adam(model.parameters(), 5e-4), \"binary_crossentropy\",\n",
    "              metrics=['binary_crossentropy'], )\n",
    "\n",
    "history = model.fit(train_model_input,lbe.fit_transform(train[target].values),epochs=30,verbose=2,validation_split=0.25)\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "print(f'{log_loss(test[target].values, pred_ans):.5f}')"
   ]
  }
 ]
}
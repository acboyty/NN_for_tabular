{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('py37_pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b5079757533a07d523b22964b5bda6a42550d36e9c94eb5f662e38c34376cbf3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Prepare data\n",
    "\n",
    "## Main process\n",
    "* Load raw data\n",
    "* Generate X/Y, Convert to ndarray and Save\n",
    "* Generate cat_cols list, Convert to int and Save\n",
    "* save column names for future analysis\n",
    "* Save task type: 2-class, m-class, regression\n",
    "\n",
    "## Some illustration\n",
    "* numeric feature in float64 type, categorical feature in object(str) type\n",
    "* NaNs are converted to np.nan(numeric) and 'NaN'(categorical)\n",
    "* split data into train/val/test in **utils.data_loader** function, because there are several possible ways of splitting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import StringIO\n",
    "import re \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult, Amazon, Click prediction, KDD appetency, KDD churn, KDD internet, KDD upselling, KDD 98, Kick prediction\n",
    "# \n",
    "# San Francisco,\n",
    "dataset = 'San Francisco'  \n",
    "dataset_path = \"/home/v-tyan/NN_for_tabular/datasets_raw/\"\n",
    "\n",
    "dataset2type = {'Adult': '2-class', 'Amazon': '2-class', 'Click prediction': '2-class', 'KDD appetency': '2-class', 'KDD churn': '2-class', 'KDD upselling': '2-class', 'KDD 98': '2-class', 'Kick prediction': '2-class', 'KDD internet': '2-class',\n",
    "\n",
    "'San Francisco': 'm-class'}\n",
    "\n",
    "timeseries = {'Adult': False, 'Amazon': False, 'Click prediction': False, 'KDD appetency': False, 'KDD churn': False, 'KDD upselling': False, 'KDD 98': False, 'Kick prediction': False, 'KDD internet': False, \n",
    "\n",
    "'San Francisco': True}"
   ]
  },
  {
   "source": [
    "## Adult\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Adult"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'Adult':\n",
    "    cols = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "    target_col = 'income'\n",
    "    cat_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "    num_cols = list(set(cols) - {target_col} - set(cat_cols))\n",
    "    train_df = pd.read_csv(os.path.join(dataset_path, 'Adult/adult.data'), sep=', ', header=None, names=cols, na_values='?', engine='python')\n",
    "    test_df = pd.read_csv(os.path.join(dataset_path, 'Adult/adult.test'), sep=', ', header=None, names=cols, na_values='?', engine='python')\n",
    "    test_df.replace({'<=50K.': '<=50K', '>50K.': '>50K'}, inplace=True)\n",
    "    train_X, train_Y = train_df.drop(target_col, axis=1), train_df[target_col]\n",
    "    test_X, test_Y = test_df.drop(target_col, axis=1), test_df[target_col]\n",
    "    X, Y = train_X.append(test_X, ignore_index=True), train_Y.append(test_Y, ignore_index=True)\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "## Amazon\n",
    "\n",
    "https://www.kaggle.com/c/amazon-employee-access-challenge"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'Amazon':\n",
    "    df = pd.read_csv(os.path.join(dataset_path, 'Amazon/train.csv'))\n",
    "    cols = list(df.columns)\n",
    "    target_col = 'ACTION'\n",
    "    cat_cols = list(set(set(cols) - {target_col}))\n",
    "    num_cols = []  # assume all are categorial\n",
    "    X, Y = df.drop(target_col, axis=1), df[target_col]\n",
    "    # train_idx = pd.read_csv(os.path.join(dataset_path, \"Amazon/stratified_train_idx.txt\"), header=None)\n",
    "    # test_idx = pd.read_csv(os.path.join(dataset_path, \"Amazon/stratified_test_idx.txt\"), header=None)\n",
    "    # train_X, test_X, train_Y, test_Y = X.iloc[train_idx[0]], X.iloc[test_idx[0]], Y.iloc[train_idx[0]], Y.iloc[test_idx[0]]\n",
    "    # X, Y = train_X.append(test_X, ignore_index=True), train_Y.append(test_Y, ignore_index=True)\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "## Click prediction\n",
    "\n",
    "https://www.kdd.org/kdd-cup/view/kdd-cup-2012-track-2\n",
    "\n",
    "subsampling according to https://github.com/catboost/benchmarks/tree/master/quality_benchmarks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'Click prediction':\n",
    "    cols = ['click', 'impression', 'url_hash', 'ad_id', 'advertiser_id', 'depth', 'position', 'query_id', 'keyword_id', 'title_id', 'description_id', 'user_id']\n",
    "    target_col = 'click'\n",
    "    cat_cols = ['impression', 'url_hash', 'ad_id', 'position', 'query_id', 'keyword_id', 'title_id', 'description_id']\n",
    "    num_cols = list(set(cols) - {target_col} - set(cat_cols))\n",
    "    with open(os.path.join(dataset_path, \"Click prediction/track2/subsampling_idx.txt\")) as fin:\n",
    "        ids = list(map(int, fin.read().split()))\n",
    "    unique_ids = set(ids)\n",
    "    data_strings = {}\n",
    "    with open(os.path.join(dataset_path, \"Click prediction/track2/training.txt\")) as fin:\n",
    "        for i, string in enumerate(fin):\n",
    "            if i in unique_ids:\n",
    "                data_strings[i] = string\n",
    "    data_rows = []\n",
    "    for i in ids:\n",
    "        data_rows.append(data_strings[i])\n",
    "    df = pd.read_table(StringIO(\"\".join(data_rows)), header=None, names=cols)    \n",
    "    X, Y = df.drop(target_col, axis=1), df[target_col].apply(lambda x: 1 if x == 0 else -1)  # convert to 2-class\n",
    "    def clean_string(s):\n",
    "        return \"v_\" + re.sub('[^A-Za-z0-9]+', \"_\", str(s))\n",
    "    for cat_col in cat_cols:\n",
    "        X[cat_col] = X[cat_col].apply(clean_string)\n",
    "    # train_idx = pd.read_csv(os.path.join(dataset_path, \"Click prediction/track2/stratified_train_idx.txt\"), header=None)\n",
    "    # test_idx = pd.read_csv(os.path.join(dataset_path, \"Click prediction/track2/stratified_test_idx.txt\"), header=None)\n",
    "    # train_X, test_X, train_Y, test_Y = X.iloc[train_idx[0]], X.iloc[test_idx[0]], Y.iloc[train_idx[0]], Y.iloc[test_idx[0]]\n",
    "    # X, Y = train_X.append(test_X, ignore_index=True), train_Y.append(test_Y, ignore_index=True)\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "## KDD appetency, churn, upselling\n",
    "\n",
    "https://www.kdd.org/kdd-cup/view/kdd-cup-2009/Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset in {'KDD appetency', 'KDD churn', 'KDD upselling'}:\n",
    "    df = pd.read_csv(os.path.join(dataset_path, \"appetency_churn_upselling/orange_small_train.data\"), sep = \"\\t\")\n",
    "    cols = list(df.columns)\n",
    "    cat_cols = [cols[idx] for idx in [190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
    "                207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228]]\n",
    "    num_cols = list(set(cols) - set(cat_cols))\n",
    "    dataset_ = dataset.split(' ')[-1]\n",
    "    X, Y = df, -pd.read_csv(os.path.join(dataset_path, f'appetency_churn_upselling/orange_small_train_{dataset_}.labels'), header=None)[0]\n",
    "    # train_idx = pd.read_csv(os.path.join(dataset_path, f'appetency_churn_upselling/{dataset_}/stratified_train_idx_{dataset_}.txt'), header=None)\n",
    "    # test_idx = pd.read_csv(os.path.join(dataset_path, f'appetency_churn_upselling/{dataset_}/stratified_test_idx_{dataset_}.txt'), header=None)\n",
    "    # train_X, test_X, train_Y, test_Y = X.iloc[train_idx[0]], X.iloc[test_idx[0]], Y.iloc[train_idx[0]], Y.iloc[test_idx[0]]\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "## San Francisco Crime Classification\n",
    "\n",
    "https://www.kaggle.com/c/sf-crime/data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'San Francisco':\n",
    "    df = pd.read_csv(os.path.join(dataset_path, \"San Francisco/train.csv\"))\n",
    "    cols = ['Category', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y']  # desert Dates attribute\n",
    "    df = df[cols]\n",
    "    df = df.reindex(list(range(len(df) - 1, -1, -1)))\n",
    "    target_col = 'Category'\n",
    "    cat_cols = ['DayOfWeek', 'PdDistrict', 'Address']\n",
    "    num_cols = ['X', 'Y']\n",
    "    X, Y = df.drop(target_col, axis=1), df[target_col]\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "## Prepare numerical features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[num_cols] = X[num_cols].astype(np.float64)\n",
    "if dataset in {}:\n",
    "    Y = Y.astype(np.float64)"
   ]
  },
  {
   "source": [
    "## Prepare category features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_col in cat_cols:\n",
    "    X[cat_col] = X[cat_col].apply(str)\n",
    "if dataset in {'Adult', 'Amazon', 'Click prediction', 'KDD appetency', 'KDD churn', 'KDD internet', 'KDD upselling', 'KDD 98', 'Kick prediction'}:\n",
    "    Y = Y.apply(str)"
   ]
  },
  {
   "source": [
    "## Convert to ndarray and int"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset in {'Adult', 'Amazon', 'Click prediction', 'KDD appetency', 'KDD churn', 'KDD upselling'}:\n",
    "    cat_cols_ = []\n",
    "    for idx, col in enumerate(X.columns):\n",
    "        if col in cat_cols:\n",
    "            cat_cols_.append(idx)\n",
    "    cat_cols = cat_cols_\n",
    "    X, Y = X.values, Y.values"
   ]
  },
  {
   "source": [
    "## Save"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "data = X, Y, cat_cols, columns, dataset2type[dataset], timeseries[dataset]\n",
    "save_dir = f\"/home/v-tyan/NN_for_tabular/datasets/{dataset}.npy\"\n",
    "np.save(save_dir, data)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(878049, 5) (878049,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('py37_pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b5079757533a07d523b22964b5bda6a42550d36e9c94eb5f662e38c34376cbf3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Prepare data\n",
    "\n",
    "## Main process\n",
    "* Load raw data\n",
    "* Generate X/Y, Convert to ndarray and Save\n",
    "* Generate cat_cols list, Convert to int and Save\n",
    "* save column names for future analysis\n",
    "* Save task type: 2-class, m-class, regression\n",
    "\n",
    "## Some illustration\n",
    "* numeric feature in float64 type, categorical feature in object(str) type\n",
    "* NaNs are converted to np.nan(numeric) and 'NaN'(categorical)\n",
    "* split data into train/val/test in **utils.data_loader** function, because there are several possible ways of splitting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import StringIO\n",
    "import re \n",
    "import pickle\n",
    "import scipy.io.arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult, Amazon, Click prediction, KDD appetency, KDD churn, KDD upselling, HIGGS, KDD internet, Kick prediction\n",
    "# San Francisco,\n",
    "# Rossmann,\n",
    "dataset = 'Kick prediction'  \n",
    "dataset_path = \"/home/v-tyan/NN_for_tabular/datasets_raw/\"\n",
    "\n",
    "dataset2type = {\n",
    "'Adult': '2-class', 'Amazon': '2-class', 'Click prediction': '2-class', 'KDD appetency': '2-class', 'KDD churn': '2-class', 'KDD upselling': '2-class', 'KDD 98': '2-class', 'Kick prediction': '2-class', 'KDD internet': '2-class', 'HIGGS': '2-class',\n",
    "'San Francisco': 'm-class', \n",
    "'Rossmann': 'regression', \n",
    "}\n",
    "\n",
    "timeseries = {\n",
    "'Adult': False, 'Amazon': False, 'Click prediction': False, 'KDD appetency': False, 'KDD churn': False, 'KDD upselling': False, 'KDD 98': False, 'Kick prediction': False, 'KDD internet': False, 'HIGGS': False, \n",
    "'San Francisco': True,\n",
    "'Rossmann': False, \n",
    "}"
   ]
  },
  {
   "source": [
    "## Adult\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Adult"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'Adult':\n",
    "    cols = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "    target_col = 'income'\n",
    "    cat_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "    num_cols = list(set(cols) - {target_col} - set(cat_cols))\n",
    "    train_df = pd.read_csv(os.path.join(dataset_path, 'Adult/adult.data'), sep=', ', header=None, names=cols, na_values='?', engine='python')\n",
    "    test_df = pd.read_csv(os.path.join(dataset_path, 'Adult/adult.test'), sep=', ', header=None, names=cols, na_values='?', engine='python')\n",
    "    test_df.replace({'<=50K.': '<=50K', '>50K.': '>50K'}, inplace=True)\n",
    "    train_X, train_Y = train_df.drop(target_col, axis=1), train_df[target_col]\n",
    "    test_X, test_Y = test_df.drop(target_col, axis=1), test_df[target_col]\n",
    "    X, Y = train_X.append(test_X, ignore_index=True), train_Y.append(test_Y, ignore_index=True)\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "## Amazon\n",
    "\n",
    "https://www.kaggle.com/c/amazon-employee-access-challenge"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'Amazon':\n",
    "    df = pd.read_csv(os.path.join(dataset_path, 'Amazon/train.csv'))\n",
    "    cols = list(df.columns)\n",
    "    target_col = 'ACTION'\n",
    "    cat_cols = list(set(set(cols) - {target_col}))\n",
    "    num_cols = []  # assume all are categorial\n",
    "    X, Y = df.drop(target_col, axis=1), df[target_col]\n",
    "    # train_idx = pd.read_csv(os.path.join(dataset_path, \"Amazon/stratified_train_idx.txt\"), header=None)\n",
    "    # test_idx = pd.read_csv(os.path.join(dataset_path, \"Amazon/stratified_test_idx.txt\"), header=None)\n",
    "    # train_X, test_X, train_Y, test_Y = X.iloc[train_idx[0]], X.iloc[test_idx[0]], Y.iloc[train_idx[0]], Y.iloc[test_idx[0]]\n",
    "    # X, Y = train_X.append(test_X, ignore_index=True), train_Y.append(test_Y, ignore_index=True)\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "## Click prediction\n",
    "\n",
    "https://www.kdd.org/kdd-cup/view/kdd-cup-2012-track-2\n",
    "\n",
    "subsampling according to https://github.com/catboost/benchmarks/tree/master/quality_benchmarks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'Click prediction':\n",
    "    cols = ['click', 'impression', 'url_hash', 'ad_id', 'advertiser_id', 'depth', 'position', 'query_id', 'keyword_id', 'title_id', 'description_id', 'user_id']\n",
    "    target_col = 'click'\n",
    "    cat_cols = ['impression', 'url_hash', 'ad_id', 'position', 'query_id', 'keyword_id', 'title_id', 'description_id']\n",
    "    num_cols = list(set(cols) - {target_col} - set(cat_cols))\n",
    "    with open(os.path.join(dataset_path, \"Click prediction/track2/subsampling_idx.txt\")) as fin:\n",
    "        ids = list(map(int, fin.read().split()))\n",
    "    unique_ids = set(ids)\n",
    "    data_strings = {}\n",
    "    with open(os.path.join(dataset_path, \"Click prediction/track2/training.txt\")) as fin:\n",
    "        for i, string in enumerate(fin):\n",
    "            if i in unique_ids:\n",
    "                data_strings[i] = string\n",
    "    data_rows = []\n",
    "    for i in ids:\n",
    "        data_rows.append(data_strings[i])\n",
    "    df = pd.read_table(StringIO(\"\".join(data_rows)), header=None, names=cols)    \n",
    "    X, Y = df.drop(target_col, axis=1), df[target_col].apply(lambda x: 1 if x == 0 else -1)  # convert to 2-class\n",
    "    def clean_string(s):\n",
    "        return \"v_\" + re.sub('[^A-Za-z0-9]+', \"_\", str(s))\n",
    "    for cat_col in cat_cols:\n",
    "        X[cat_col] = X[cat_col].apply(clean_string)\n",
    "    # train_idx = pd.read_csv(os.path.join(dataset_path, \"Click prediction/track2/stratified_train_idx.txt\"), header=None)\n",
    "    # test_idx = pd.read_csv(os.path.join(dataset_path, \"Click prediction/track2/stratified_test_idx.txt\"), header=None)\n",
    "    # train_X, test_X, train_Y, test_Y = X.iloc[train_idx[0]], X.iloc[test_idx[0]], Y.iloc[train_idx[0]], Y.iloc[test_idx[0]]\n",
    "    # X, Y = train_X.append(test_X, ignore_index=True), train_Y.append(test_Y, ignore_index=True)\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "## KDD appetency, churn, upselling\n",
    "\n",
    "https://www.kdd.org/kdd-cup/view/kdd-cup-2009/Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset in {'KDD appetency', 'KDD churn', 'KDD upselling'}:\n",
    "    df = pd.read_csv(os.path.join(dataset_path, \"appetency_churn_upselling/orange_small_train.data\"), sep = \"\\t\")\n",
    "    cols = list(df.columns)\n",
    "    cat_cols = [cols[idx] for idx in [190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
    "                207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228]]\n",
    "    num_cols = list(set(cols) - set(cat_cols))\n",
    "    dataset_ = dataset.split(' ')[-1]\n",
    "    X, Y = df, -pd.read_csv(os.path.join(dataset_path, f'appetency_churn_upselling/orange_small_train_{dataset_}.labels'), header=None)[0]\n",
    "    # train_idx = pd.read_csv(os.path.join(dataset_path, f'appetency_churn_upselling/{dataset_}/stratified_train_idx_{dataset_}.txt'), header=None)\n",
    "    # test_idx = pd.read_csv(os.path.join(dataset_path, f'appetency_churn_upselling/{dataset_}/stratified_test_idx_{dataset_}.txt'), header=None)\n",
    "    # train_X, test_X, train_Y, test_Y = X.iloc[train_idx[0]], X.iloc[test_idx[0]], Y.iloc[train_idx[0]], Y.iloc[test_idx[0]]\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "## HIGGS Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/HIGGS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'HIGGS':\n",
    "    df = pd.read_csv(os.path.join(dataset_path, \"Higgs Boson/HIGGS.csv\"), header=None)\n",
    "    cols = list(df.columns)\n",
    "    target_col = 0\n",
    "    cat_cols = []\n",
    "    num_cols = list(set(cols) - {target_col} - set(cat_cols))\n",
    "    X, Y = df.drop(target_col, axis=1), df[target_col]\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "##  Rossmann Store Sales\n",
    "\n",
    "https://www.kaggle.com/c/rossmann-store-sales/data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'Rossmann':\n",
    "    df = pd.read_csv(os.path.join(dataset_path, \"Rossmann/train.csv\"))\n",
    "    cols = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday']\n",
    "    target_col = 'Sales'\n",
    "    cat_cols = ['Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday']\n",
    "    num_cols = ['Customers']\n",
    "    X, Y = df.drop(target_col, axis=1), df[target_col]\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "## San Francisco Crime Classification\n",
    "\n",
    "https://www.kaggle.com/c/sf-crime/data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'San Francisco':\n",
    "    df = pd.read_csv(os.path.join(dataset_path, \"San Francisco/train.csv\"))\n",
    "    cols = ['Category', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y']  # desert Dates attribute\n",
    "    df = df[cols]\n",
    "    df = df.reindex(list(range(len(df) - 1, -1, -1)))\n",
    "    target_col = 'Category'\n",
    "    cat_cols = ['DayOfWeek', 'PdDistrict', 'Address']\n",
    "    num_cols = ['X', 'Y']\n",
    "    X, Y = df.drop(target_col, axis=1), df[target_col]\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "##  KDD internet\n",
    "\n",
    "https://www.cs.odu.edu/~mukka/cs795sum10dm/datasets/uci-20070111/nominal/kdd_internet_usage.arff"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'KDD internet':\n",
    "    df = pd.read_csv(os.path.join(dataset_path, \"KDD internet/kdd_internet_usage.csv\"), header=None)\n",
    "    cols = list(range(69))\n",
    "    df = df[cols]\n",
    "    target_col = 68\n",
    "    cat_cols = [0, 1, 2, 11, 12, 18, 19, 20, 21, 31, 32, 33, 34, 36, 37, 38, 39, 59, 60, 61, 62]\n",
    "    num_cols = list(set(cols) - {target_col} - set(cat_cols))\n",
    "    Y = df[target_col].apply(lambda x: 1 if x == '0' else -1)\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    columns = X.columns"
   ]
  },
  {
   "source": [
    "## Kick prediction\n",
    "\n",
    "https://www.kaggle.com/c/DontGetKicked/data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(72983, 35)"
      ]
     },
     "metadata": {},
     "execution_count": 280
    }
   ],
   "source": [
    "if dataset == 'Kick prediction':\n",
    "    data = pd.read_csv(os.path.join(dataset_path, \"Kick prediction/training.csv\"))\n",
    "    target = data[\"IsBadBuy\"].apply(lambda x: 1.0 if x == 0 else -1.0)\n",
    "    data[\"PurchYear\"] = pd.DatetimeIndex(data['PurchDate']).year\n",
    "    data[\"PurchMonth\"] = pd.DatetimeIndex(data['PurchDate']).month\n",
    "    data[\"PurchDay\"] = pd.DatetimeIndex(data['PurchDate']).day\n",
    "    data[\"PurchWeekday\"] = pd.DatetimeIndex(data['PurchDate']).weekday\n",
    "    data.drop([\"RefId\", \"IsBadBuy\", \"PurchDate\"], axis=1, inplace=True)\n",
    "    X = data\n",
    "    Y = target\n",
    "    columns = X.columns\n",
    "    cat_cols = [columns[i] for i in [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34]]\n",
    "    num_cols = list(set(columns) - set(cat_cols))\n",
    "X.shape"
   ]
  },
  {
   "source": [
    "## Prepare numerical features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[num_cols] = X[num_cols].astype(np.float64)\n",
    "if dataset in {'Rossmann'}:\n",
    "    Y = Y.astype(np.float64)"
   ]
  },
  {
   "source": [
    "## Prepare category features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_col in cat_cols:\n",
    "    X[cat_col] = X[cat_col].apply(str)\n",
    "if dataset in {'Adult', 'Amazon', 'Click prediction', 'KDD appetency', 'KDD churn', 'KDD internet', 'KDD upselling', 'KDD 98', 'Kick prediction'}:\n",
    "    Y = Y.apply(str)"
   ]
  },
  {
   "source": [
    "## Convert to ndarray and int"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dataset in {'Adult', 'Amazon', 'Click prediction', 'KDD appetency', 'KDD churn', 'KDD upselling', 'San Francisco'}:\n",
    "cat_cols_ = []\n",
    "for idx, col in enumerate(X.columns):\n",
    "    if col in cat_cols:\n",
    "        cat_cols_.append(idx)\n",
    "cat_cols = cat_cols_\n",
    "X, Y = X.values, Y.values"
   ]
  },
  {
   "source": [
    "## Save"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "data = X, Y, cat_cols, columns, dataset2type[dataset], timeseries[dataset]\n",
    "save_dir = f\"/home/v-tyan/NN_for_tabular/datasets/{dataset}.npy\"\n",
    "np.save(save_dir, data)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 284,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(72983, 35) (72983,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  }
 ]
}